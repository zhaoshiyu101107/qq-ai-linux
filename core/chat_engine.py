"""
å¯¹è¯å¼•æ“æ¨¡å—
"""

import torch
from typing import List, Dict, Any
from core.model_loader import ModelLoader

class ChatEngine:
    """å¯¹è¯å¼•æ“"""
    
    def __init__(self, model_key: str = 'qwen2.5-0.5b'):
        self.model_key = model_key
        self.loader = ModelLoader(model_key)
        self.tokenizer = None
        self.model = None
        self.chat_history = []
        
    def initialize(self):
        """åˆå§‹åŒ–å¯¹è¯å¼•æ“"""
        print("ğŸš€ åˆå§‹åŒ–å¯¹è¯å¼•æ“...")
        self.tokenizer, self.model = self.loader.load()
        print("âœ… å¯¹è¯å¼•æ“å°±ç»ª")
        
    def chat(self, 
             user_input: str, 
             max_tokens: int = 200,
             temperature: float = 0.7,
             top_p: float = 0.95,
             add_to_history: bool = True) -> str:
        """å•æ¬¡å¯¹è¯"""
        if self.model is None:
            self.initialize()
        
        # å‡†å¤‡æ¶ˆæ¯
        messages = [{"role": "user", "content": user_input}]
        
        # åº”ç”¨èŠå¤©æ¨¡æ¿
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # ç¼–ç è¾“å…¥
        inputs = self.tokenizer(text, return_tensors="pt").to(self.model.device)
        
        # ç”Ÿæˆå›å¤
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # è§£ç å›å¤
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # æ¸…ç†å›å¤
        response = self._clean_response(response)
        
        # æ·»åŠ åˆ°å†å²
        if add_to_history:
            self.chat_history.append({
                'user': user_input,
                'assistant': response,
                'tokens': outputs.shape[1]
            })
        
        return response
    
    def _clean_response(self, response: str) -> str:
        """æ¸…ç†å›å¤æ–‡æœ¬"""
        # ç§»é™¤æç¤ºéƒ¨åˆ†
        markers = ['assistant', 'Assistant:', 'AI:', 'Bot:']
        
        for marker in markers:
            if marker in response:
                response = response.split(marker)[-1].strip()
                break
        
        # ç§»é™¤å¯èƒ½çš„ç‰¹æ®Šæ ‡è®°
        response = response.replace('<|endoftext|>', '').strip()
        
        return response
    
    def interactive_chat(self, 
                        max_tokens: int = 200,
                        temperature: float = 0.7,
                        top_p: float = 0.95):
        """äº¤äº’å¼å¯¹è¯"""
        if self.model is None:
            self.initialize()
        
        print("\n" + "="*60)
        print(f"ğŸ¤– {self.model_key} å¯¹è¯æ¨¡å¼")
        print("="*60)
        print("ğŸ’¡ å‘½ä»¤:")
        print("  /clear  - æ¸…ç©ºå†å²")
        print("  /history - æŸ¥çœ‹å†å²")
        print("  /quit   - é€€å‡º")
        print("="*60)
        
        while True:
            try:
                user_input = input("\nä½ : ").strip()
                
                # å¤„ç†å‘½ä»¤
                if user_input.lower() in ['/quit', '/exit', 'quit', 'exit']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                elif user_input.lower() == '/clear':
                    self.chat_history.clear()
                    print("ğŸ—‘ï¸  å†å²å·²æ¸…ç©º")
                    continue
                elif user_input.lower() == '/history':
                    self.print_history()
                    continue
                elif not user_input:
                    continue
                
                # ç”Ÿæˆå›å¤
                print("æ€è€ƒä¸­...", end="", flush=True)
                response = self.chat(
                    user_input, 
                    max_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p
                )
                print("\r" + " " * 20 + "\r", end="")  # æ¸…é™¤"æ€è€ƒä¸­..."
                print(f"AI: {response}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ”š é€€å‡ºå¯¹è¯")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
    
    def print_history(self):
        """æ‰“å°å¯¹è¯å†å²"""
        if not self.chat_history:
            print("ğŸ“­ å¯¹è¯å†å²ä¸ºç©º")
            return
        
        print(f"\nğŸ“œ å¯¹è¯å†å² ({len(self.chat_history)} æ¡):")
        print("-"*60)
        
        for i, entry in enumerate(self.chat_history, 1):
            print(f"{i}. ä½ : {entry['user'][:50]}...")
            print(f"   AI: {entry['assistant'][:50]}...")
            print()
    
    def save_history(self, filename: str = "chat_history.txt"):
        """ä¿å­˜å¯¹è¯å†å²"""
        import json
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.chat_history, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å†å²å·²ä¿å­˜åˆ°: {filename}")