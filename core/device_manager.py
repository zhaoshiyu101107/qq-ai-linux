"""
è®¾å¤‡ç®¡ç†æ¨¡å—
"""

import torch
from typing import Dict, List, Any
from config.gpu_config import detect_gpus, get_gpu_memory_info

class DeviceManager:
    """è®¾å¤‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.gpus = detect_gpus()
        self.config = None
        
    def print_device_info(self):
        """æ‰“å°è®¾å¤‡ä¿¡æ¯"""
        print("=" * 60)
        print("ğŸ® è®¾å¤‡æ£€æµ‹æŠ¥å‘Š")
        print("=" * 60)
        
        if not self.gpus:
            print("âŒ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡")
            print("ğŸ’¡ å°†ä½¿ç”¨CPUè¿è¡Œ")
            return False
        
        print(f"âœ… æ£€æµ‹åˆ° {len(self.gpus)} ä¸ªGPU:")
        print("-" * 60)
        
        for gpu in self.gpus:
            mem_info = get_gpu_memory_info(gpu['id'])
            print(f"  GPU {gpu['id']}: {gpu['name']}")
            print(f"     æ˜¾å­˜: {mem_info.get('allocated_gb', 0):.1f}/{gpu['memory_total_gb']:.1f} GB")
            print(f"     ç®—åŠ›: CUDA {gpu['capability']}")
            print()
        
        return True
    
    def get_user_choice(self) -> Dict:
        """è·å–ç”¨æˆ·è®¾å¤‡é€‰æ‹©"""
        if not self.gpus:
            return {
                'device': 'cpu',
                'device_map': 'cpu',
                'torch_dtype': torch.float32,
                'use_gpu': False
            }
        
        print("\né€‰æ‹©GPUä½¿ç”¨æ–¹å¼:")
        print("1. ğŸš€ è‡ªåŠ¨é€‰æ‹©æœ€ä½³GPU")
        print("2. ğŸ”¢ æ‰‹åŠ¨é€‰æ‹©GPU")
        print("3. ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPU")
        print("-" * 40)
        
        while True:
            choice = input("è¯·é€‰æ‹© (1-3, é»˜è®¤: 1): ").strip()
            
            if not choice:
                choice = "1"
            
            if choice == "1":
                return self._auto_select()
            elif choice == "2":
                return self._manual_select()
            elif choice == "3":
                return {
                    'device': 'cpu',
                    'device_map': 'cpu',
                    'torch_dtype': torch.float32,
                    'use_gpu': False
                }
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def _auto_select(self) -> Dict:
        """è‡ªåŠ¨é€‰æ‹©GPU"""
        best_gpu = max(self.gpus, key=lambda x: x['memory_total_gb'])
        
        print(f"\nâœ… è‡ªåŠ¨é€‰æ‹©: GPU {best_gpu['id']} ({best_gpu['name']})")
        print(f"   æ˜¾å­˜: {best_gpu['memory_total_gb']:.1f} GB")
        
        return {
            'device': f"cuda:{best_gpu['id']}",
            'device_map': f"cuda:{best_gpu['id']}",
            'torch_dtype': torch.float16,
            'use_gpu': True,
            'selected_gpu_id': best_gpu['id']
        }
    
    def _manual_select(self) -> Dict:
        """æ‰‹åŠ¨é€‰æ‹©GPU"""
        print("\nå¯ç”¨GPU:")
        for gpu in self.gpus:
            print(f"  [{gpu['id']}] {gpu['name']} ({gpu['memory_total_gb']:.1f} GB)")
        
        while True:
            try:
                selection = input("\né€‰æ‹©GPU (è¾“å…¥åºå·, å¦‚: 0): ").strip()
                gpu_id = int(selection)
                
                if gpu_id not in [g['id'] for g in self.gpus]:
                    raise ValueError(f"GPU {gpu_id} ä¸å­˜åœ¨")
                
                selected_gpu = next(g for g in self.gpus if g['id'] == gpu_id)
                print(f"âœ… é€‰æ‹©: GPU {gpu_id} ({selected_gpu['name']})")
                
                return {
                    'device': f"cuda:{gpu_id}",
                    'device_map': f"cuda:{gpu_id}",
                    'torch_dtype': torch.float16,
                    'use_gpu': True,
                    'selected_gpu_id': gpu_id
                }
                
            except (ValueError, TypeError) as e:
                print(f"âŒ é”™è¯¯: {e}")
                print("è¯·é‡æ–°è¾“å…¥")