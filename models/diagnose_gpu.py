#venv/bin/env python3
"""
GPUè¯Šæ–­è„šæœ¬ - æ‰¾å‡ºä¸ºä»€ä¹ˆè„šæœ¬æ£€æµ‹ä¸åˆ°GPU
"""

import torch
import subprocess
import os
import sys

def check_pytorch_gpu():
    """æ£€æŸ¥PyTorchæ˜¯å¦èƒ½æ£€æµ‹åˆ°GPU"""
    print("=" * 60)
    print("ğŸ® PyTorch GPUæ£€æµ‹")
    print("=" * 60)
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAç¼–è¯‘ç‰ˆæœ¬: {torch.version.cuda if hasattr(torch.version, 'cuda') else 'None'}")
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    cuda_available = torch.cuda.is_available()
    print(f"torch.cuda.is_available(): {cuda_available}")
    
    if cuda_available:
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"  GPU {i}: {props.name}")
            print(f"     æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB")
            print(f"     ç®—åŠ›: {props.major}.{props.minor}")
    else:
        print("âŒ PyTorchæ— æ³•è®¿é—®GPU")
    
    return cuda_available

def check_nvidia_driver():
    """æ£€æŸ¥NVIDIAé©±åŠ¨"""
    print("\n" + "=" * 60)
    print("ğŸ› ï¸  NVIDIAé©±åŠ¨æ£€æµ‹")
    print("=" * 60)
    
    try:
        # å°è¯•è¿è¡Œnvidia-smi
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… nvidia-smiå‘½ä»¤å¯ç”¨")
            
            # æå–é©±åŠ¨ç‰ˆæœ¬
            lines = result.stdout.split('\n')
            for line in lines:
                if 'Driver Version' in line:
                    print(f"  é©±åŠ¨ç‰ˆæœ¬: {line.strip()}")
                    break
            
            # æå–GPUä¿¡æ¯
            for line in lines:
                if 'NVIDIA' in line and 'GB' in line:
                    print(f"  GPUä¿¡æ¯: {line.strip()}")
            
            return True
        else:
            print("âŒ nvidia-smiå‘½ä»¤å¤±è´¥")
            print(f"  é”™è¯¯: {result.stderr}")
            return False
            
    except FileNotFoundError:
        print("âŒ nvidia-smiæœªæ‰¾åˆ°")
        print("  å¯èƒ½åŸå› :")
        print("  1. NVIDIAé©±åŠ¨æœªå®‰è£…")
        print("  2. nvidia-smiä¸åœ¨PATHä¸­")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥é©±åŠ¨æ—¶å‡ºé”™: {e}")
        return False

def check_cuda_installation():
    """æ£€æŸ¥CUDAå®‰è£…"""
    print("\n" + "=" * 60)
    print("ğŸ“¦ CUDAå®‰è£…æ£€æµ‹")
    print("=" * 60)
    
    # æ£€æŸ¥å¸¸è§çš„CUDAè·¯å¾„
    cuda_paths = [
        "/usr/local/cuda",
        "/usr/local/cuda/bin",
        "/opt/cuda",
        "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA"
    ]
    
    found_cuda = False
    for path in cuda_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°CUDAç›®å½•: {path}")
            found_cuda = True
            
            # æ£€æŸ¥nvcc
            nvcc_path = os.path.join(path, "bin", "nvcc")
            if os.path.exists(nvcc_path):
                print(f"  nvccå­˜åœ¨: {nvcc_path}")
            else:
                print(f"  nvccä¸å­˜åœ¨äº: {nvcc_path}")
    
    if not found_cuda:
        print("âŒ æœªæ‰¾åˆ°CUDAå®‰è£…ç›®å½•")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\nğŸ“ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    env_vars = ['CUDA_HOME', 'CUDA_PATH', 'PATH']
    for var in env_vars:
        value = os.environ.get(var, 'æœªè®¾ç½®')
        if var == 'PATH':
            print(f"  {var}: (é•¿åº¦: {len(value)} å­—ç¬¦)")
            # æ£€æŸ¥PATHä¸­æ˜¯å¦åŒ…å«CUDA
            if 'cuda' in value.lower():
                print(f"    PATHä¸­åŒ…å«CUDA")
        else:
            print(f"  {var}: {value}")
    
    return found_cuda

def check_pytorch_installation_type():
    """æ£€æŸ¥PyTorchå®‰è£…ç±»å‹ï¼ˆCPU/GPUï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ” PyTorchå®‰è£…ç±»å‹æ£€æµ‹")
    print("=" * 60)
    
    # æ£€æŸ¥PyTorchæ˜¯å¦æ”¯æŒCUDA
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥ç¼–è¯‘é€‰é¡¹
        print(f"ç¼–è¯‘æ—¶CUDAæ”¯æŒ: {'æ˜¯' if torch.cuda.is_available() else 'å¦'}")
        
        # å°è¯•å¯¼å…¥cudaæ¨¡å—
        try:
            import torch.cuda
            print(f"torch.cudaæ¨¡å—: å¯å¯¼å…¥")
            
            # æ£€æŸ¥_cudaæ¨¡å—
            if hasattr(torch, '_C'):
                print(f"torch._Cå­˜åœ¨: æ˜¯")
            else:
                print(f"torch._Cå­˜åœ¨: å¦")
                
        except ImportError as e:
            print(f"torch.cudaå¯¼å…¥å¤±è´¥: {e}")
            print("âš ï¸  è¿™å¯èƒ½æ˜¯CPUç‰ˆæœ¬çš„PyTorch")
            
    except Exception as e:
        print(f"æ£€æŸ¥PyTorchæ—¶å‡ºé”™: {e}")
    
    # æ£€æŸ¥pipå®‰è£…çš„åŒ…
    print("\nğŸ”§ æ£€æŸ¥å·²å®‰è£…çš„PyTorchåŒ…:")
    try:
        result = subprocess.run([sys.executable, '-m', 'pip', 'list', '|', 'grep', 'torch'], 
                              capture_output=True, text=True, shell=True)
        if result.returncode == 0:
            print(result.stdout)
    except:
        pass

def check_gpu_with_lspci():
    """ä½¿ç”¨lspciæ£€æŸ¥GPUï¼ˆLinuxï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ’» ç³»ç»Ÿç¡¬ä»¶æ£€æµ‹")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥lspciï¼ˆLinuxï¼‰
        result = subprocess.run(['lspci'], capture_output=True, text=True)
        if result.returncode == 0:
            gpu_lines = [line for line in result.stdout.split('\n') 
                        if 'VGA' in line or '3D' in line or 'Display' in line]
            
            if gpu_lines:
                print("âœ… ç³»ç»Ÿæ£€æµ‹åˆ°æ˜¾å¡:")
                for line in gpu_lines:
                    print(f"  {line}")
            else:
                print("âŒ ç³»ç»Ÿä¸­æœªæ£€æµ‹åˆ°æ˜¾å¡è®¾å¤‡")
        else:
            print("âš ï¸  lspciå‘½ä»¤ä¸å¯ç”¨")
            
    except FileNotFoundError:
        print("âš ï¸  lspciå‘½ä»¤æœªæ‰¾åˆ°ï¼ˆå¯èƒ½ä¸æ˜¯Linuxç³»ç»Ÿï¼‰")
    except Exception as e:
        print(f"æ£€æŸ¥ç¡¬ä»¶æ—¶å‡ºé”™: {e}")

def check_arch_specific():
    """Arch Linuxç‰¹å®šæ£€æŸ¥"""
    print("\n" + "=" * 60)
    print("ğŸ§ Arch Linuxç‰¹å®šæ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†cudaåŒ…
    try:
        result = subprocess.run(['pacman', '-Q', 'cuda'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… ç³»ç»Ÿå·²å®‰è£…CUDAåŒ…")
            print(f"  ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ ç³»ç»Ÿæœªå®‰è£…CUDAåŒ…")
            
        # æ£€æŸ¥nvidiaé©±åŠ¨åŒ…
        nvidia_packages = ['nvidia', 'nvidia-utils', 'nvidia-settings']
        for pkg in nvidia_packages:
            result = subprocess.run(['pacman', '-Q', pkg], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… å·²å®‰è£…: {pkg}")
            else:
                print(f"âŒ æœªå®‰è£…: {pkg}")
                
    except Exception as e:
        print(f"æ£€æŸ¥ArchåŒ…æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("ğŸ¤– GPUè¯Šæ–­å·¥å…·")
    print("=" * 60)
    print("æ­¤å·¥å…·å°†å¸®åŠ©è¯Šæ–­ä¸ºä»€ä¹ˆè„šæœ¬æ£€æµ‹ä¸åˆ°GPU")
    print("=" * 60)
    
    # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
    import platform
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    
    # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
    pytorch_gpu = check_pytorch_gpu()
    nvidia_driver = check_nvidia_driver()
    cuda_installed = check_cuda_installation()
    check_pytorch_installation_type()
    
    if platform.system() == 'Linux':
        check_gpu_with_lspci()
        if 'arch' in platform.platform().lower():
            check_arch_specific()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
    print("=" * 60)
    
    issues = []
    
    if not pytorch_gpu:
        issues.append("âŒ PyTorchæ— æ³•æ£€æµ‹åˆ°GPU")
    if not nvidia_driver:
        issues.append("âŒ NVIDIAé©±åŠ¨å¯èƒ½æœ‰é—®é¢˜")
    if not cuda_installed:
        issues.append("âš ï¸  CUDAå¯èƒ½æœªæ­£ç¡®å®‰è£…")
    
    if issues:
        print("å‘ç°ä»¥ä¸‹é—®é¢˜:")
        for issue in issues:
            print(f"  {issue}")
        
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®ä¿å®‰è£…äº†NVIDIAé©±åŠ¨")
        print("2. å®‰è£…CUDAå·¥å…·åŒ…")
        print("3. é‡æ–°å®‰è£…GPUç‰ˆæœ¬çš„PyTorch:")
        print("   pip uninstall torch torchvision torchaudio")
        print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    else:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        print("å¦‚æœè„šæœ¬ä»ç„¶æ£€æµ‹ä¸åˆ°GPUï¼Œè¯·æ£€æŸ¥è„šæœ¬ä¸­çš„æ£€æµ‹é€»è¾‘")
    
    print("\nğŸ”§ å¿«é€Ÿä¿®å¤å‘½ä»¤:")
    print("å®‰è£…GPUç‰ˆPyTorch:")
    print("  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")

if __name__ == "__main__":
    main()