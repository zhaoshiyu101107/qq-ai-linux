#!/usr/bin/env python3
"""
PyTorch GPUç‰ˆæœ¬ä¿®å¤è„šæœ¬
ä¸“é—¨é’ˆå¯¹Arch Linuxå’ŒCPUç‰ˆæœ¬é—®é¢˜
"""

import subprocess
import sys
import os

def run_command(cmd, desc=""):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    if desc:
        print(f"ğŸ“¦ {desc}...")
    
    print(f"   $ {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"   âœ… æˆåŠŸ")
            if result.stdout.strip():
                print(f"     è¾“å‡º: {result.stdout[:200]}...")
            return True
        else:
            print(f"   âŒ å¤±è´¥")
            if result.stderr:
                print(f"     é”™è¯¯: {result.stderr[:200]}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"   â³ è¶…æ—¶ï¼Œæ­£åœ¨ç»§ç»­...")
        return True
    except Exception as e:
        print(f"   âŒ å¼‚å¸¸: {e}")
        return False

def check_current_pytorch():
    """æ£€æŸ¥å½“å‰PyTorchç‰ˆæœ¬"""
    print("ğŸ” æ£€æŸ¥å½“å‰PyTorchå®‰è£…...")
    
    try:
        result = subprocess.run(
            [sys.executable, '-c', 'import torch; print(torch.__version__)'],
            capture_output=True, text=True
        )
        
        if result.returncode == 0:
            version = result.stdout.strip()
            print(f"   å½“å‰ç‰ˆæœ¬: {version}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯CPUç‰ˆæœ¬
            if '+cpu' in version.lower():
                print("   âŒ æ£€æµ‹åˆ°CPUç‰ˆæœ¬çš„PyTorch")
                return True, version  # Trueè¡¨ç¤ºéœ€è¦ä¿®å¤
            else:
                print("   âœ… å·²ç»æ˜¯GPUç‰ˆæœ¬")
                return False, version
        else:
            print("   â“ æ— æ³•è·å–ç‰ˆæœ¬")
            return True, "unknown"
            
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return True, "error"

def check_cuda_driver():
    """æ£€æŸ¥CUDAé©±åŠ¨"""
    print("\nğŸ® æ£€æŸ¥CUDAé©±åŠ¨...")
    
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        
        if result.returncode == 0:
            # è§£ænvidia-smiè¾“å‡º
            lines = result.stdout.split('\n')
            for line in lines:
                if 'Driver Version' in line:
                    driver = line.split('Driver Version:')[-1].split()[0]
                    print(f"   é©±åŠ¨ç‰ˆæœ¬: {driver}")
                
                if 'CUDA Version' in line:
                    cuda = line.split('CUDA Version:')[-1].split()[0]
                    print(f"   æ”¯æŒCUDAç‰ˆæœ¬: {cuda}")
            
            print("   âœ… NVIDIAé©±åŠ¨æ­£å¸¸")
            return True
        else:
            print("   âŒ nvidia-smiå¤±è´¥")
            return False
            
    except FileNotFoundError:
        print("   âŒ nvidia-smiæœªæ‰¾åˆ°")
        return False
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return False

def get_cuda_version_from_driver():
    """ä»é©±åŠ¨è·å–CUDAç‰ˆæœ¬"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'],
            capture_output=True, text=True
        )
        
        if result.returncode == 0:
            driver_version = result.stdout.strip()
            # ç®€åŒ–ï¼šæ ¹æ®é©±åŠ¨ç‰ˆæœ¬æ¨æµ‹CUDAç‰ˆæœ¬
            driver_major = int(driver_version.split('.')[0])
            
            # é©±åŠ¨ç‰ˆæœ¬åˆ°CUDAç‰ˆæœ¬çš„æ˜ å°„ï¼ˆç®€åŒ–ï¼‰
            if driver_major >= 580:  # 580.xæ”¯æŒCUDA 12.x
                return "12.1"
            elif driver_major >= 525:  # 525.xæ”¯æŒCUDA 11.8
                return "11.8"
            elif driver_major >= 470:  # 470.xæ”¯æŒCUDA 11.4
                return "11.7"
            else:
                return "11.8"  # é»˜è®¤
                
        return "11.8"  # é»˜è®¤
        
    except:
        return "11.8"  # é»˜è®¤

def install_gpu_pytorch():
    """å®‰è£…GPUç‰ˆæœ¬çš„PyTorch"""
    print("\nğŸš€ å®‰è£…GPUç‰ˆæœ¬PyTorch")
    print("="*60)
    
    # 1. å¸è½½å½“å‰ç‰ˆæœ¬
    print("1ï¸âƒ£  å¸è½½å½“å‰CPUç‰ˆæœ¬...")
    success = run_command(
        [sys.executable, '-m', 'pip', 'uninstall', '-y', 
         'torch', 'torchvision', 'torchaudio'],
        "å¸è½½PyTorch"
    )
    
    if not success:
        print("âš ï¸  å¸è½½å¯èƒ½å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶å¸è½½...")
        run_command([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch'])
    
    # 2. æ ¹æ®é©±åŠ¨é€‰æ‹©CUDAç‰ˆæœ¬
    print("\n2ï¸âƒ£  é€‰æ‹©CUDAç‰ˆæœ¬...")
    cuda_version = get_cuda_version_from_driver()
    print(f"   æ ¹æ®é©±åŠ¨é€‰æ‹©: CUDA {cuda_version}")
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    versions = {
        "1": ("11.8", "https://download.pytorch.org/whl/cu118"),
        "2": ("12.1", "https://download.pytorch.org/whl/cu121"),
        "3": ("12.4", "https://download.pytorch.org/whl/cu124"),
    }
    
    print("\n   å¯é€‰ç‰ˆæœ¬:")
    for key, (ver, url) in versions.items():
        print(f"   [{key}] CUDA {ver}")
    
    choice = input(f"\n   é€‰æ‹©ç‰ˆæœ¬ (1-3, é»˜è®¤ {cuda_version}): ").strip()
    
    if choice in versions:
        selected_ver, index_url = versions[choice]
    else:
        # ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬
        for ver, url in versions.values():
            if ver == cuda_version:
                selected_ver, index_url = cuda_version, url
                break
        else:
            selected_ver, index_url = versions["1"]  # é»˜è®¤11.8
    
    print(f"   ä½¿ç”¨: CUDA {selected_ver} ({index_url})")
    
    # 3. å®‰è£…GPUç‰ˆæœ¬
    print(f"\n3ï¸âƒ£  å®‰è£…CUDA {selected_ver} ç‰ˆæœ¬çš„PyTorch...")
    
    # å¯¹äºArch Linuxï¼Œå¯èƒ½éœ€è¦--break-system-packages
    is_arch = os.path.exists('/etc/arch-release')
    
    pip_cmd = [sys.executable, '-m', 'pip', 'install']
    
    if is_arch:
        pip_cmd.append('--break-system-packages')
        print("   ğŸ§ æ£€æµ‹åˆ°Arch Linuxï¼Œä½¿ç”¨--break-system-packages")
    
    pip_cmd.extend(['torch', 'torchvision', 'torchaudio'])
    pip_cmd.extend(['--index-url', index_url])
    
    success = run_command(pip_cmd, "å®‰è£…GPUç‰ˆæœ¬")
    
    if not success:
        print("\nâš ï¸  å®‰è£…å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ¸…åé•œåƒæº...")
        
        # å°è¯•æ¸…åé•œåƒ
        pip_cmd = [sys.executable, '-m', 'pip', 'install']
        if is_arch:
            pip_cmd.append('--break-system-packages')
        
        pip_cmd.extend(['torch', 'torchvision', 'torchaudio', '-i', 
                       'https://pypi.tuna.tsinghua.edu.cn/simple'])
        
        run_command(pip_cmd, "ä½¿ç”¨æ¸…åé•œåƒå®‰è£…")
    
    return success

def verify_installation():
    """éªŒè¯å®‰è£…"""
    print("\nâœ… éªŒè¯å®‰è£…...")
    
    try:
        # è¿è¡ŒPythonä»£ç æ£€æŸ¥
        check_code = """
import torch
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"  GPU {i}: {props.name}")
        print(f"      æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB")
else:
    print("âŒ GPUä»ç„¶ä¸å¯ç”¨")
"""
        
        result = subprocess.run(
            [sys.executable, '-c', check_code],
            capture_output=True, text=True
        )
        
        print(result.stdout)
        
        if torch.cuda.is_available() in result.stdout:
            return True
        else:
            return False
            
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    print("ğŸ¤– PyTorch GPUç‰ˆæœ¬ä¿®å¤å·¥å…·")
    print("="*60)
    
    # æ£€æŸ¥å½“å‰å®‰è£…
    need_fix, current_version = check_current_pytorch()
    
    if not need_fix and '+cpu' not in current_version.lower():
        print("\nâœ… å½“å‰å·²ç»æ˜¯GPUç‰ˆæœ¬ï¼Œæ— éœ€ä¿®å¤")
        return
    
    # æ£€æŸ¥é©±åŠ¨
    driver_ok = check_cuda_driver()
    
    if not driver_ok:
        print("\nâŒ NVIDIAé©±åŠ¨æœ‰é—®é¢˜ï¼Œè¯·å…ˆå®‰è£…é©±åŠ¨:")
        print("   sudo pacman -S nvidia nvidia-utils nvidia-settings")
        return
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    print("\n" + "="*60)
    response = input("æ˜¯å¦å®‰è£…GPUç‰ˆæœ¬çš„PyTorchï¼Ÿ(Y/n): ").strip().lower()
    
    if response in ['', 'y', 'yes']:
        # å®‰è£…
        success = install_gpu_pytorch()
        
        if success:
            # éªŒè¯
            verify_installation()
            
            print("\n" + "="*60)
            print("ğŸ‰ ä¿®å¤å®Œæˆï¼")
            print("ç°åœ¨å¯ä»¥è¿è¡Œä½ çš„AIè„šæœ¬äº†")
            print("="*60)
        else:
            print("\nâŒ å®‰è£…å¤±è´¥")
            print("è¯·å°è¯•æ‰‹åŠ¨å®‰è£…:")
            print("  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    else:
        print("\nâŒ ç”¨æˆ·å–æ¶ˆ")
    
    print("\nğŸ’¡ è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•GPU:")
    print("  python -c \"import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}')\"")

if __name__ == "__main__":
    main()